name: Train Ensemble ML Model

on:
  workflow_dispatch:
    inputs:
      version:
        description: "Model version (e.g. v3)"
        required: false
        default: "v3"
      model_type:
        description: "Model type"
        required: false
        default: "ensemble"
        type: choice
        options:
          - ensemble
          - xgboost
          - random_forest
          - logistic
      label_type:
        description: "Label type"
        required: false
        default: "multiclass"
        type: choice
        options:
          - binary
          - multiclass
          - regression
      years:
        description: "Years of historical data"
        required: false
        default: "10"
      horizon:
        description: "Prediction horizon (days)"
        required: false
        default: "20"
      max_tickers:
        description: "Max tickers for training"
        required: false
        default: "75"

jobs:
  train-ensemble:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_BUCKET: ${{ secrets.SUPABASE_BUCKET }}
      SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scripts/ml/requirements.txt

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential jq

      - name: Install Python dependencies
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: '1'
          # Install heavy ML libraries with wheels when possible
          PIP_ONLY_BINARY: "numpy,pandas,scipy,scikit-learn,xgboost,lightgbm"
        run: |
          python -m pip install --upgrade pip
          # Install core dependencies first
          pip install "numpy>=1.24.0" "pandas>=2.0.0" "scikit-learn>=1.3.0" requests
          # Install ML libraries with specific versions that work well in CI
          pip install "xgboost>=2.0.0" "lightgbm>=4.0.0" "shap>=0.44.0"
          # Install utility libraries
          pip install "vaderSentiment>=3.3.0" "optuna>=3.4.0" "optuna-integration[xgboost]>=1.0.0" "plotly>=5.17.0" "seaborn>=0.13.0"
          # Verify installations
          python -c "import xgboost, lightgbm, shap, pandas, numpy, sklearn; print('All ML libraries installed successfully')"

      - name: Train ensemble model
        run: |
          python scripts/ml/train_model_ensemble.py \
            --out-dir ml_out \
            --version "${{ github.event.inputs.version || 'v3' }}" \
            --model-type "${{ github.event.inputs.model_type || 'ensemble' }}" \
            --label-type "${{ github.event.inputs.label_type || 'multiclass' }}" \
            --years "${{ github.event.inputs.years || '3' }}" \
            --horizon "${{ github.event.inputs.horizon || '20' }}" \
            --max-tickers "${{ github.event.inputs.max_tickers || '10' }}"

      - name: List outputs
        run: |
          ls -la ml_out/
          echo "Model files:"
          find ml_out -name "*.json" -exec echo "File: {}" \; -exec head -20 {} \;

      - name: Upload model to Supabase Storage
        run: |
          set -euo pipefail
          LATEST_FILE="ml_out/latest.json"
          if [ ! -f "$LATEST_FILE" ]; then echo "latest.json missing"; exit 1; fi

          # Extract the model path from latest.json
          MODEL_PATH=$(jq -r '.path' "$LATEST_FILE")
          MODEL_BASENAME=$(basename "$MODEL_PATH")
          MODEL_FILE="ml_out/${MODEL_BASENAME}"

          if [ ! -f "$MODEL_FILE" ]; then
            echo "Model file not found: $MODEL_FILE"
            echo "Available files:"
            ls -la ml_out/
            exit 1
          fi

          DEST_PATH="ml/models/${MODEL_BASENAME}"

          echo "Uploading $MODEL_FILE to $DEST_PATH"
          curl -sS -X POST \
            "${SUPABASE_URL%/}/storage/v1/object/${SUPABASE_BUCKET}/${DEST_PATH}" \
            -H "Authorization: Bearer ${SUPABASE_SERVICE_ROLE}" \
            -H "apikey: ${SUPABASE_SERVICE_ROLE}" \
            -H "x-upsert: true" \
            --data-binary @"${MODEL_FILE}" \
            -o /dev/null -w '%{http_code}' | tee /tmp/upcode

          code=$(cat /tmp/upcode)
          if [ "$code" != "200" ] && [ "$code" != "201" ]; then
            echo "Upload failed with code: $code"
            exit 1
          fi
          echo "Upload successful with code: $code"

      - name: Upload latest pointer
        run: |
          set -euo pipefail
          LATEST_FILE="ml_out/latest.json"
          if [ ! -f "$LATEST_FILE" ]; then echo "latest.json missing"; exit 1; fi

          echo "Uploading latest.json"
          curl -sS -X POST \
            "${SUPABASE_URL%/}/storage/v1/object/${SUPABASE_BUCKET}/ml/models/latest.json" \
            -H "Authorization: Bearer ${SUPABASE_SERVICE_ROLE}" \
            -H "apikey: ${SUPABASE_SERVICE_ROLE}" \
            -H "x-upsert: true" \
            --data-binary @"${LATEST_FILE}" \
            -o /dev/null -w '%{http_code}' | tee /tmp/upcode

          code=$(cat /tmp/upcode)
          if [ "$code" != "200" ] && [ "$code" != "201" ]; then
            echo "Latest upload failed with code: $code"
            exit 1
          fi
          echo "Latest upload successful with code: $code"


      - name: Upload artifacts to Hugging Face Hub
        env:
          HF_API_TOKEN: ${{ secrets.HF_API_TOKEN }}
        run: |
          set -euo pipefail
          REPO_ID="${HF_HUB_REPO_ID:-Kjaehr/stock_dashboard_models}"
          SUBDIR="${HF_HUB_SUBDIR:-ensembles/}"

          echo "Repo id: ${REPO_ID}"
          echo "Target subdir: ${SUBDIR}"

          # Find the newest bundle ZIP in ml_out (created by training script)
          ZIP_FILE=$(ls -1t ml_out/*.zip 2>/dev/null | head -n1 || true)
          if [ -z "${ZIP_FILE}" ]; then
            echo "ERROR: No bundle .zip found in ml_out/ (expected ensemble_..._.zip)" >&2
            ls -la ml_out/ || true
            exit 1
          fi

          # Determine size in bytes
          if command -v stat >/dev/null 2>&1; then
            if stat --version >/dev/null 2>&1; then
              SIZE=$(stat -c%s "${ZIP_FILE}")
            else
              SIZE=$(stat -f%z "${ZIP_FILE}")
            fi
          else
            SIZE=0
          fi
          MAX=$((2*1024*1024*1024))

          BASENAME=$(basename "${ZIP_FILE}")
          BASE_NOEXT="${BASENAME%.zip}"
          JSON_FILE="ml_out/${BASE_NOEXT}.json"
          LATEST_FILE="ml_out/latest.json"

          # Optional files
          OOF_MAIN="ml_out/oof.csv"
          mapfile -t OOF_FOLDS < <(ls -1 ml_out/*oof*.csv 2>/dev/null || true)

          echo "Preparing to upload to Hugging Face Hub..."
          echo "Artifact: ${ZIP_FILE} (${SIZE} bytes)"

          python -m pip install --upgrade "huggingface_hub>=0.24.0"
          export HF_TOKEN="${HF_API_TOKEN}"
          export HUGGINGFACE_HUB_TOKEN="${HF_API_TOKEN}"

          # Ensure repo exists (private)
          hf repo create "${REPO_ID}" --private --type model -y >/dev/null 2>&1 || true

          upload_with_retry() {
            local src="$1"; local dst="$2"; local attempt
            for attempt in 1 2 3; do
              if hf upload "${REPO_ID}" "${src}" "${dst}" --repo-type model --private --quiet; then
                echo "Uploaded: ${dst}"
                return 0
              fi
              sleep $((2**(attempt-1)))
            done
            return 1
          }

          FAILED=0

          if [ "${SIZE}" -lt "${MAX}" ]; then
            echo "Using standard upload (git/LFS-style) via hf upload"
            if ! upload_with_retry "${ZIP_FILE}" "${SUBDIR}${BASENAME}"; then FAILED=1; fi
          else
            echo "Using large-file upload via huggingface-cli (S3 multi-part)"
            for attempt in 1 2 3; do
              if huggingface-cli upload "${REPO_ID}" "${ZIP_FILE}" "${SUBDIR}${BASENAME}" --repo-type model --private --quiet; then
                echo "Uploaded (large-file): ${SUBDIR}${BASENAME}"
                break
              fi
              sleep $((2**(attempt-1)))
            done
          fi

          # Optional companions
          if [ -f "${JSON_FILE}" ]; then upload_with_retry "${JSON_FILE}" "${SUBDIR}${BASE_NOEXT}.json" || FAILED=1; fi
          if [ -f "${LATEST_FILE}" ]; then upload_with_retry "${LATEST_FILE}" "${SUBDIR}latest.json" || FAILED=1; fi
          if [ -f "${OOF_MAIN}" ]; then upload_with_retry "${OOF_MAIN}" "${SUBDIR}oof.csv" || FAILED=1; fi
          for f in ml_out/*oof*.csv; do
            [ -f "$f" ] || continue
            [ "$(basename "$f")" = "oof.csv" ] && continue
            upload_with_retry "$f" "${SUBDIR}$(basename "$f")" || FAILED=1
          done

          if [ "$FAILED" -ne 0 ]; then
            echo "ERROR: One or more uploads failed" >&2
            exit 1
          fi

          # Update ml_out/latest.json to point to Hub bundle (for services that follow HF)
          VERSION="$(jq -r '.version // empty' "${LATEST_FILE}" 2>/dev/null || true)"
          if [ -z "${VERSION}" ]; then VERSION="${BASE_NOEXT}"; fi
          jq -n --arg repo_id "${REPO_ID}" \
                --arg path_in_repo "${SUBDIR}${BASENAME}" \
                --arg version "${VERSION}" \
                --arg uploaded_at "$(date -u +%FT%SZ)" \
                '{repo_id:$repo_id, path_in_repo:$path_in_repo, version:$version, uploaded_at:$uploaded_at}' \
            > ml_out/latest.json

          echo "Upload OK"
          echo "repo_id: ${REPO_ID}"
          echo "path_in_repo (.zip): ${SUBDIR}${BASENAME}"
          echo "Repo: https://huggingface.co/${REPO_ID}"
          echo "File: https://huggingface.co/${REPO_ID}/resolve/main/${SUBDIR}${BASENAME}"
          [ -f "${JSON_FILE}" ] && echo "File: https://huggingface.co/${REPO_ID}/resolve/main/${SUBDIR}${BASE_NOEXT}.json"
          [ -f "${LATEST_FILE}" ] && echo "File: https://huggingface.co/${REPO_ID}/resolve/main/${SUBDIR}latest.json"
          [ -f "${OOF_MAIN}" ] && echo "File: https://huggingface.co/${REPO_ID}/resolve/main/${SUBDIR}oof.csv"


      - name: Summary
        run: |
          echo "ðŸŽ‰ Ensemble model training completed!"
          echo "Model type: ${{ github.event.inputs.model_type || 'ensemble' }}"
          echo "Label type: ${{ github.event.inputs.label_type || 'multiclass' }}"
          echo "Version: ${{ github.event.inputs.version || 'v3' }}"
          echo ""
          echo "Next steps:"
          echo "1. Check model performance in uploaded JSON"
          echo "2. Test model in your application"
          echo "3. Compare with previous model versions"
